{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "18faf3d6",
      "metadata": {
        "id": "18faf3d6"
      },
      "source": [
        "## Phase 1: Data Understanding & Preparation\n",
        "## Step 1: Dataset Exploration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import warnings"
      ],
      "metadata": {
        "id": "G59AGzYqPcPm"
      },
      "id": "G59AGzYqPcPm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "292ecb82",
      "metadata": {
        "id": "292ecb82"
      },
      "outputs": [],
      "source": [
        "data_dir = \"C:/Users/People/Desktop/PPLafrica/Specialisation/AI-SoftwareDev/week4-intelSoft/assignment/src/predictive_analytics/data/complete_set\"\n",
        "\n",
        "# 2) Build the train/test sub-paths\n",
        "training_benign_dir    = os.path.join(data_dir, 'training_set', 'benign')\n",
        "training_malignant_dir = os.path.join(data_dir, 'training_set', 'malignant')\n",
        "testing_data_dir       = os.path.join(data_dir, 'testing_set')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c416115",
      "metadata": {
        "id": "0c416115"
      },
      "source": [
        "## Step 2: Image Visualization & Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwrXK3DPFXxt"
      },
      "outputs": [],
      "source": [
        "def visualize_samples():\n",
        "    \"\"\"Visualize sample images from each class\"\"\"\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
        "\n",
        "    # Benign samples\n",
        "    benign_path = os.path.join(TRAIN_PATH, \"benign\")\n",
        "    benign_files = os.listdir(benign_path)[:5]\n",
        "\n",
        "    for i, file in enumerate(benign_files):\n",
        "        img = cv2.imread(os.path.join(benign_path, file))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        axes[0, i].imshow(img)\n",
        "        axes[0, i].set_title(f\"Benign {i+1}\")\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "    # Malignant samples\n",
        "    malignant_path = os.path.join(TRAIN_PATH, \"malignant\")\n",
        "    malignant_files = os.listdir(malignant_path)[:5]\n",
        "\n",
        "    for i, file in enumerate(malignant_files):\n",
        "        img = cv2.imread(os.path.join(malignant_path, file))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        axes[1, i].imshow(img)\n",
        "        axes[1, i].set_title(f\"Malignant {i+1}\")\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sample_images.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "visualize_samples()"
      ],
      "id": "BwrXK3DPFXxt"
    },
    {
      "cell_type": "markdown",
      "id": "e6066fcc",
      "metadata": {
        "id": "e6066fcc"
      },
      "source": [
        "## Step 3: Image Preprocessing & Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44455415",
      "metadata": {
        "id": "44455415"
      },
      "outputs": [],
      "source": [
        "# Image parameters\n",
        "IMG_SIZE = 224  # Standard for transfer learning models\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "# Data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    validation_split=0.2  # 20% for validation\n",
        ")\n",
        "\n",
        "# Training generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Test generator (no augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "print(f\"Training samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {validation_generator.samples}\")\n",
        "print(f\"Class indices: {train_generator.class_indices}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c6ad9da",
      "metadata": {
        "id": "5c6ad9da"
      },
      "source": [
        "## Phase 2: Model Architecture & Training\n",
        "### Step 4: Transfer Learning Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c79ef36",
      "metadata": {
        "id": "2c79ef36"
      },
      "outputs": [],
      "source": [
        "def create_transfer_learning_model(base_model_name='VGG16'):\n",
        "    \"\"\"Create transfer learning model\"\"\"\n",
        "\n",
        "    if base_model_name == 'VGG16':\n",
        "        base_model = tf.keras.applications.VGG16(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "        )\n",
        "    elif base_model_name == 'ResNet50':\n",
        "        base_model = tf.keras.applications.ResNet50(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "        )\n",
        "    elif base_model_name == 'EfficientNetB0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "        )\n",
        "\n",
        "    # Freeze base model\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add custom head\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create and compile models\n",
        "models_to_try = ['VGG16', 'ResNet50', 'EfficientNetB0']\n",
        "trained_models = {}\n",
        "\n",
        "for model_name in models_to_try:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {model_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    model = create_transfer_learning_model(model_name)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=5,\n",
        "            min_lr=1e-7\n",
        "        ),\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            f'best_model_{model_name.lower()}.h5',\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    trained_models[model_name] = {\n",
        "        'model': model,\n",
        "        'history': history\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eb5d74f",
      "metadata": {
        "id": "5eb5d74f"
      },
      "source": [
        "## Step 5: Model Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d76494fe",
      "metadata": {
        "id": "d76494fe"
      },
      "outputs": [],
      "source": [
        "def fine_tune_model(model, base_model_name):\n",
        "    \"\"\"Fine-tune the best performing model\"\"\"\n",
        "\n",
        "    # Unfreeze some layers of the base model\n",
        "    base_model = model.layers[0]\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Fine-tune from this layer onwards\n",
        "    fine_tune_at = len(base_model.layers) // 2\n",
        "\n",
        "    # Freeze all the layers before fine_tune_at\n",
        "    for layer in base_model.layers[:fine_tune_at]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Use a lower learning rate for fine-tuning\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001/10),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "\n",
        "    # Fine-tune\n",
        "    fine_tune_epochs = 10\n",
        "    total_epochs = EPOCHS + fine_tune_epochs\n",
        "\n",
        "    history_fine = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "        epochs=total_epochs,\n",
        "        initial_epoch=EPOCHS,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model, history_fine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "191d8751",
      "metadata": {
        "id": "191d8751"
      },
      "source": [
        "## Phase 3: Model Evaluation & Analysis\n",
        "### Step 6: Comprehensive Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6a15c4",
      "metadata": {
        "id": "fb6a15c4"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, model_name):\n",
        "    \"\"\"Comprehensive model evaluation\"\"\"\n",
        "\n",
        "    # Predictions on validation set\n",
        "    validation_generator.reset()\n",
        "    predictions = model.predict(validation_generator)\n",
        "    predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "    # True labels\n",
        "    true_classes = validation_generator.classes\n",
        "\n",
        "    # Metrics\n",
        "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "    precision = precision_score(true_classes, predicted_classes)\n",
        "    recall = recall_score(true_classes, predicted_classes)\n",
        "    f1 = f1_score(true_classes, predicted_classes)\n",
        "    auc = roc_auc_score(true_classes, predictions)\n",
        "\n",
        "    print(f\"\\n{model_name} Performance:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(true_classes, predicted_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(f'confusion_matrix_{model_name.lower()}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'auc': auc\n",
        "    }\n",
        "\n",
        "# Evaluate all models\n",
        "results = {}\n",
        "for model_name, model_data in trained_models.items():\n",
        "    results[model_name] = evaluate_model(model_data['model'], model_name)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}